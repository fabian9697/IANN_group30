{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise B-Splines\n",
    "\n",
    "This week's exercise is about a variation of linear regression and model selection. You may define auxiliary functions if you think it improves the clarity of your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# execute this cell to import all the numpy and matplotlib functions you need.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. B-splines\n",
    "---\n",
    "Last week you implemented a linear regression using monomial basis functions. Depending on the underlying function, polynomial basis functions are not always the best choice. In the lecture B-splines were introduced, which are local and picewise polynomial functions. Piecewise polynomial simple means that it is a combination of polynomials. The following figure shows the B-spline $B_{0,3}$ with so called knots of (-3,-2,-1,0).\n",
    "\n",
    "![b-spline](b-spline.png)\n",
    "\n",
    "Knots or break-points are the values on the X-axis where one polynomial ends and another starts. In the figure you can see that a new polynomial starts for example at knot -3 and goes until knot -2. B-splines are also local basis function, which means that they are only non-zero on a finite intervall. The B-spline in the figure is for values smaller than -3 and bigger than 0 equal to 0. This property makes them especially usefull for certain tasks of linear regression, since you can place them exacly where you want them to have an influence. B-splines are defined recursively:\n",
    "\n",
    "$$ B_{k,1}(x) = \\left\\{ \\begin{matrix} 1 & \\mathrm{if} \\quad t_k \\leq x < t_{k+1} \\\\ 0 & \\mathrm{else} \\end{matrix} \\right.$$\n",
    "\n",
    "$$B_{k,d}(x) = \\frac{x - t_k}{t_{k+d-1} - t_k} B_{k,d-1}(x) + \\frac{t_{k+d} - x}{t_{k+d} - t_{k+1}} B_{k+1,d-1}(x)$$\n",
    "\n",
    "$t_k$ referes to the knot at index $k$, $d$ is the degree of the polynomial used to construct the spline. For information see script page 55.\n",
    "\n",
    "\n",
    "The function `get_bspline` in the following cell, is a so called function factory (a function that returns another function). You can see that `bspline` is defined inside `get_bspline`. The last line of the outer function returns a vectorized version of the inner function, i.e. when called with an array-like value for x, the bspline function is applied elementwise to every cell. Sample usage:\n",
    "\n",
    "```\n",
    "bspline = get_bspline(knots=[0,1,2,3,4])\n",
    "x = linspace(0,4,10)\n",
    "y = bspline(x, k=0, d=3)\n",
    "```\n",
    "1. Plot all B-splines of degree three, for eleven equidistant knots between zero and ten (inclusive).\n",
    "2. Given a total number of $m$ knots and an arbitrary positive integer for $d$, what is the maximal value of $k$ ? *(Note that the first knot index is 0)*\n",
    "3. Try out different degrees or strange knot placements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_bspline(knots):\n",
    "    \"\"\" Takes an array-like parameter and returns a function implementing a B-spline. \"\"\"\n",
    "    \n",
    "    def bspline(x, k, d): \n",
    "        if d==1: # recursion stop\n",
    "            if knots[k] <= x < knots[k+1]:\n",
    "                y = 1\n",
    "            else:\n",
    "                y = 0\n",
    "        else:\n",
    "            factor1 = (x-knots[k])/(knots[k+d-1]-knots[k])\n",
    "            factor2 = (knots[k+d]-x)/(knots[k+d]-knots[k+1])\n",
    "            b1 = bspline(x, k, d-1)   # recursion!\n",
    "            b2 = bspline(x, k+1, d-1) # recursion!\n",
    "            y = factor1*b1 + factor2*b2\n",
    "        return y\n",
    "\n",
    "    return np.vectorize(bspline, excluded=['k','d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Your Code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Cubic B-spline linear regression\n",
    "---\n",
    "\n",
    "Implement a function that performs a linear regression using $(B_{0,d}, \\dots, B_{m-d-1,d})$ as basis functions. Use `pinv` for calculating the pseudoinverse.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def bspline_regression(X, Y, knots, deg):\n",
    "    \"\"\"\n",
    "    Performes a B-spline regression.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 1-D ndarray\n",
    "        samples of the independent variable\n",
    "    Y : 1-D ndarray\n",
    "        samples of the dependent variable\n",
    "    knots : 1-D array-like\n",
    "        knots of the splines\n",
    "    deg : integer\n",
    "        order of splines\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    w : ndarray\n",
    "        egression weights\n",
    "    \"\"\"\n",
    "\n",
    "    #-- enter code here --#\n",
    "    \n",
    "    return w\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Fit, choose, plot \n",
    "-----\n",
    "Load the data from *BSplinesCrossValidationHyperparameters_data.csv*. You will find a 2x200 array, the first column of which is the indepent, the second column the dependent variable. Look at the data and your plot from above to find a good knot array for a B-spline regression (at this point it is not important to find the best model, we do that later). Fit a model with the knots of your choice to the data and plot the resulting graph together with a scatter plot of the data. Briefly describe why you chose those specific knots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Your Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Cross-validation\n",
    "----\n",
    "\n",
    "You may have noticed that no underlying target function is given this time. This is the typical case in real applications. The most popular approach to verify your fit in this case is cross-validation. Implement a 10-fold cross-validation and validate the model you chose in task 3. Print the mean and the standard deviation of the RMSE of your predidictions versus the validation data. Make sure the partition of the data is randomized.\n",
    "\n",
    "The following instructions are meant as a help. You may or may not follow them.\n",
    "\n",
    "(assuming you stored your data in `X` and `Y`)\n",
    "* create a list of length `len(X)` of indices\n",
    "* shuffle that list\n",
    "* split the indices into ten equally sized chunks\n",
    "* For the chunk $c\\in \\{1,\\dots,10\\}$ do the following:\n",
    "    * use the data correspondeing to the indices in $c$ as validation data (`X_val` and `Y_val`)\n",
    "    * use the data corresponding to remaining 9 chunks as training data (´X_train´ and ´Y_train´)\n",
    "    * fit your chosen spline model on the training data\n",
    "    * make an estimation with your model on the validation data (store it in ´Y_est´)\n",
    "    * calculate the RMSE between your estimation and the validation data\n",
    "* Calculate the mean and standard deviation of the errors\n",
    "\n",
    "*Functions: mean, std, ravel, delete, shuffle*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cross_validate() missing 4 required positional arguments: 'x', 'y', 'spline_model', and 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-cbfa5c28db23>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;31m# get the mean and standard deviation of the errors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m mu, sd = cross_validate(\n\u001b[0m\u001b[0;32m     50\u001b[0m     \u001b[1;31m# all the parameters of this function are needed from the prevoius tasks to be passed to this function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: cross_validate() missing 4 required positional arguments: 'x', 'y', 'spline_model', and 'model'"
     ]
    }
   ],
   "source": [
    "def rmse(x,y):\n",
    "    return np.sqrt(np.sum((x-y)**2)/len(x))\n",
    "\n",
    "# Your Code\n",
    "\n",
    "def cross_validate(x, y, spline_model, model):\n",
    "    \n",
    "    # create a list of length `len(X)` of indices\n",
    "    indices = np.arange(len(X))\n",
    "    \n",
    "    # shuffle that list\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    # split the indices into ten equally sized chunks\n",
    "    chunks = np.reshape(indices, (10, -1))\n",
    "    \n",
    "    # the error list\n",
    "    errors = []\n",
    "    \n",
    "    # lenght of chunks for upper range for the iteration\n",
    "    len_chunks = len(chunks)\n",
    "    \n",
    "    for index in range(len_chunks): # we have 10 setups\n",
    "        \n",
    "        # use the data correspondeing to the indices in  𝑐  as validation data (X_val and Y_val)\n",
    "        X_val, Y_val = x[chunks[index]], y[chunks[index]]\n",
    "        \n",
    "        # use the data corresponding to remaining 9 chunks as training data (´X_train´ and ´Y_train´)                   \n",
    "        remain = np.ravel(np.delete(chunks, index ,axis=0))\n",
    "        x_train, y_train = x[remain], y[remain]\n",
    "\n",
    "        # fit your chosen spline model on the training data\n",
    "        fitted_model = spline_model(x_train, y_train)\n",
    "        \n",
    "        # make an estimation with your model on the validation data (store it in ´Y_est´)\n",
    "        Y_est = model(X_val, fitted_model)\n",
    "        \n",
    "        # calculate the RMSE between your estimation and the validation data\n",
    "        calculated_rmse = rmse(Y_est, Y_val)\n",
    "        \n",
    "        # adding the error of this chunk to the error list\n",
    "        errors.append(calculated_rmse)\n",
    "    \n",
    "    # calculating and returning the mean and standard deviation of the errors\n",
    "    return np.mean(errors), np.std(errors)\n",
    "\n",
    "\n",
    "# get the mean and standard deviation of the errors\n",
    "mu, sd = cross_validate(\n",
    "    # all the parameters of this function are needed from the prevoius tasks to be passed to this function\n",
    ")\n",
    "\n",
    "# the below statements give an output when the above tasks are implemented\n",
    "print(\"Mean: \", mu)\n",
    "print(\"Standard diviation: \", sd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "5. Model selection\n",
    "------\n",
    "We can distinguish two kinds of parameters. The first are coefficients in the regression model; we call them regression parameters. But there are other parameters we can manipulate in order to optimize our model. In the spline model, we can change the number of knots, the knot placement and spline degree; we call them hyper paramters.\n",
    "\n",
    "\n",
    "Write code that automatically finds a good set of hyperparamters, simply by trying different combinations of knot number, knot placement or spline degree. Use crossvalidation to determine the performance of a model. Print the regression weights, the knots and the spline degree of your best model to the console.\n",
    "\n",
    "*Hint: You can assume that the underlying function is symmetric around 0 and the 'hills' and 'valleys' have equal distance. This might reduce your search space.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Your Code"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
