{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "homework04_FI_aktuellerStand.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCIL8MFW8N6C"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYEetkLt8SWi"
      },
      "source": [
        "# Determines the maximum height and width of all images in the dataset.\n",
        "def image_max_height_max_width(dataset):\n",
        "  max_img_height = 0           \n",
        "  max_img_width = 0\n",
        "  for (input, target) in dataset:      \n",
        "    img_shape = input.shape\n",
        "    if img_shape[0] > max_img_height: \n",
        "      max_img_height = img_shape[0]\n",
        "    if img_shape[1] > max_img_width: \n",
        "      max_img_width = img_shape[1]   \n",
        "  return max_img_height, max_img_width"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeA55fQv8TjE"
      },
      "source": [
        "# Input pipeline\n",
        "size_of_dataset = 27558\n",
        "batch_size = 16\n",
        "\n",
        "raw_dataset = tfds.load('Malaria', split='train', as_supervised = True)    # Name the split parameter to get a tf.dataset with tuples. Otherwise one gets a dictionary.\n",
        "raw_dataset = raw_dataset.shuffle(size_of_dataset)                         # Shuffles the entire dataset once in the beginning. Later in the training loop shuffling with the batch_size as buffer is sufficient.\n",
        "\n",
        "\n",
        "# Pads the images to the previous detected maximum height and width of the images in the dataset.\n",
        "# Zero Padding is useful here, because the cells are presented in front of a dark background, so in this case it just increases the background surface.\n",
        "img_max_height, img_max_width = image_max_height_max_width(raw_dataset)     \n",
        "padded_images = raw_dataset.map(lambda inp, tar: tf.image.resize_with_pad(inp, img_max_height, img_max_width))\n",
        "# Standardizes the images with a mean of zero and a standard deviation of 1.\n",
        "padded_images = padded_images.map(lambda img: tf.image.per_image_standardization(img)) \n",
        "\n",
        "# One-hot encoded targets\n",
        "one_hot_targets = raw_dataset.map(lambda inp, tar: tf.one_hot(tar, 2))\n",
        "print(one_hot_targets)\n",
        "\n",
        "\n",
        "# Seperates the inputs (images) and targets into training and test data.\n",
        "splitting_limit_train_test_data = 22000\n",
        "training_dataset_inputs = padded_images.take(splitting_limit_train_test_data)      # new datasets with all items up to the splitting limit\n",
        "training_dataset_targets = one_hot_targets.take(splitting_limit_train_test_data)   \n",
        "\n",
        "test_dataset_inputs = padded_images.skip(splitting_limit_train_test_data)          # new datasets with all items from the splitting limit\n",
        "test_dataset_targets = one_hot_targets.skip(splitting_limit_train_test_data)       \n",
        "\n",
        "\n",
        "# Zips together, batches and prefetches the training and test datasets.\n",
        "training_dataset = tf.data.Dataset.zip((training_dataset_inputs, training_dataset_targets))\n",
        "training_dataset = training_dataset.batch(batch_size).prefetch(1)                  # Prefetches 1 batch of size 64\n",
        "#training_dataset = training_dataset.batch(batch_size)\n",
        "#training_dataset = training_dataset.prefetch(128)\n",
        "\n",
        "test_dataset = tf.data.Dataset.zip((test_dataset_inputs, test_dataset_targets))\n",
        "test_dataset = test_dataset.batch(batch_size).prefetch(1)   \n",
        "\n",
        "#for (img,_) in test_dataset:\n",
        "#  print(img.shape)\n",
        "#  break;"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}