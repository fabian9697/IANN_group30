{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "homework07_FI_VAR.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXn5tj9Wlf8K"
      },
      "source": [
        "**Initialization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPfIbekCi1VP"
      },
      "source": [
        "import numpy as np\r\n",
        "from sklearn.manifold import TSNE\r\n",
        "\r\n",
        "%tensorflow_version 2.x\r\n",
        "import tensorflow as tf\r\n",
        "import tensorflow_probability as tfp\r\n",
        "from tensorflow_probability import distributions as tfd\r\n",
        "from tensorflow import keras as tfk\r\n",
        "from tensorflow.keras import layers as tfkl\r\n",
        "from tensorflow_probability import layers as tfpl\r\n",
        "import tensorflow_datasets as tfds\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zg8zNL5Kll3d"
      },
      "source": [
        "**Task 1: Data set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hskeg7h3DQWh",
        "outputId": "de965c4e-8f43-414e-ba96-23e283c4e949"
      },
      "source": [
        "datasets, datasets_info = tfds.load(name='fashion_mnist',\r\n",
        "                                    with_info=True,\r\n",
        "                                    as_supervised=False)\r\n",
        "\r\n",
        "def _preprocess(sample):\r\n",
        "  image = tf.cast(sample['image'], tf.float32) / 255.  # Scale to unit interval.\r\n",
        "  image = image < tf.random.uniform(tf.shape(image))   # Randomly binarize.\r\n",
        "  return image, image\r\n",
        "\r\n",
        "training_dataset = (datasets['train']\r\n",
        "                 .map(_preprocess)\r\n",
        "                 .batch(256)\r\n",
        "                 .prefetch(tf.data.experimental.AUTOTUNE)\r\n",
        "                 .shuffle(int(10e3)))\r\n",
        "test_dataset = (datasets['test']\r\n",
        "                .map(_preprocess)\r\n",
        "                .batch(256)\r\n",
        "                .prefetch(tf.data.experimental.AUTOTUNE))\r\n",
        "\r\n",
        "for i,j in training_dataset:\r\n",
        "  print(len([i][0]))\r\n",
        "  print(len([i][0][0]))\r\n",
        "  print(len([i][0][0][0]))\r\n",
        "  print(len([i][0][0][0][0]))\r\n",
        "  print([i][0])\r\n",
        "  print([i][0][0])\r\n",
        "  print([i][0][0][0])\r\n",
        "  print([i][0][0][0][0])\r\n",
        "  break"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "256\n",
            "28\n",
            "28\n",
            "1\n",
            "tf.Tensor(\n",
            "[[[[ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   ...\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]]\n",
            "\n",
            "  [[ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   ...\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]]\n",
            "\n",
            "  [[ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   ...\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   ...\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]]\n",
            "\n",
            "  [[ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   ...\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]]\n",
            "\n",
            "  [[ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   ...\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]]]\n",
            "\n",
            "\n",
            " [[[ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   ...\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]]\n",
            "\n",
            "  [[ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   ...\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]]\n",
            "\n",
            "  [[ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   ...\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   ...\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]]\n",
            "\n",
            "  [[ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   ...\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]]\n",
            "\n",
            "  [[ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   ...\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]]]\n",
            "\n",
            "\n",
            " [[[ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   ...\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]]\n",
            "\n",
            "  [[ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   ...\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]]\n",
            "\n",
            "  [[ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   ...\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   ...\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]]\n",
            "\n",
            "  [[ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   ...\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]]\n",
            "\n",
            "  [[ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   ...\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   ...\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]]\n",
            "\n",
            "  [[ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   ...\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]]\n",
            "\n",
            "  [[ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   ...\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   ...\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]]\n",
            "\n",
            "  [[ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   ...\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]]\n",
            "\n",
            "  [[ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   ...\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]]]\n",
            "\n",
            "\n",
            " [[[ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   ...\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]]\n",
            "\n",
            "  [[ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   ...\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]]\n",
            "\n",
            "  [[ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   ...\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   ...\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]]\n",
            "\n",
            "  [[ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   ...\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]]\n",
            "\n",
            "  [[ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   ...\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]]]\n",
            "\n",
            "\n",
            " [[[ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   ...\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]]\n",
            "\n",
            "  [[ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   ...\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]]\n",
            "\n",
            "  [[ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   ...\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   ...\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]]\n",
            "\n",
            "  [[ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   ...\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]]\n",
            "\n",
            "  [[ True]\n",
            "   [ True]\n",
            "   [ True]\n",
            "   ...\n",
            "   [ True]\n",
            "   [ True]\n",
            "   [ True]]]], shape=(256, 28, 28, 1), dtype=bool)\n",
            "tf.Tensor(\n",
            "[[[ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]]\n",
            "\n",
            " [[ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [False]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]]\n",
            "\n",
            " [[ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [False]\n",
            "  [False]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]]\n",
            "\n",
            " [[ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [False]\n",
            "  [False]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]]\n",
            "\n",
            " [[ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]]\n",
            "\n",
            " [[ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [False]\n",
            "  [False]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]]\n",
            "\n",
            " [[ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [False]\n",
            "  [False]\n",
            "  [False]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]]\n",
            "\n",
            " [[ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [False]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]]\n",
            "\n",
            " [[ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [False]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]]\n",
            "\n",
            " [[ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [False]\n",
            "  [False]\n",
            "  [False]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]]\n",
            "\n",
            " [[ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [False]\n",
            "  [False]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]]\n",
            "\n",
            " [[ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [False]\n",
            "  [False]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]]\n",
            "\n",
            " [[ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [False]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]]\n",
            "\n",
            " [[ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [False]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]]\n",
            "\n",
            " [[ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]]\n",
            "\n",
            " [[ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [False]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]]\n",
            "\n",
            " [[ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [False]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]]\n",
            "\n",
            " [[ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [False]\n",
            "  [False]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]]\n",
            "\n",
            " [[ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]]\n",
            "\n",
            " [[ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [False]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]]\n",
            "\n",
            " [[ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [False]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]]\n",
            "\n",
            " [[ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [False]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]]\n",
            "\n",
            " [[ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [False]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [False]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]]\n",
            "\n",
            " [[ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [False]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]]\n",
            "\n",
            " [[ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [False]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]]\n",
            "\n",
            " [[ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]]\n",
            "\n",
            " [[ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [False]\n",
            "  [False]\n",
            "  [False]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]]\n",
            "\n",
            " [[ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [False]\n",
            "  [False]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]\n",
            "  [ True]]], shape=(28, 28, 1), dtype=bool)\n",
            "tf.Tensor(\n",
            "[[ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [False]\n",
            " [False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]], shape=(28, 1), dtype=bool)\n",
            "tf.Tensor([ True], shape=(1,), dtype=bool)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9ej7qnpo3kq"
      },
      "source": [
        "**Task 2: Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_PLfJgHr9l2"
      },
      "source": [
        "**Task 2.2: Variational Autoencoder**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNcEXXOEDxvg"
      },
      "source": [
        "Class Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVPtg904Dz3r"
      },
      "source": [
        "# Description: The class Encoder defines the encoder of a variational autoencoder.\r\n",
        "class Encoder(tf.keras.layers.Layer): \r\n",
        "  \r\n",
        "  def __init__(self):\r\n",
        "    super(Encoder, self).__init__()\r\n",
        "\r\n",
        "    self.encoded_size = 10\r\n",
        "    self.base_depth = 32\r\n",
        "\r\n",
        "    self.prior = tfd.Independent(tfd.Normal(loc=tf.zeros(self.encoded_size), scale=1), reinterpreted_batch_ndims=1)\r\n",
        "\r\n",
        "    self.input_layer = tfkl.InputLayer(input_shape=(28, 28, 1))\r\n",
        "    self.lambda_layer = tfkl.Lambda(lambda x: tf.cast(x, tf.float32) - 0.5)\r\n",
        "    self.conv_1 = tfkl.Conv2D(self.base_depth, 5, strides=1, padding='same', activation=tf.nn.leaky_relu)\r\n",
        "    self.conv_2 = tfkl.Conv2D(self.base_depth, 5, strides=2, padding='same', activation=tf.nn.leaky_relu)\r\n",
        "    self.conv_3 = tfkl.Conv2D(2 * self.base_depth, 5, strides=1, padding='same', activation=tf.nn.leaky_relu)\r\n",
        "    self.conv_4 = tfkl.Conv2D(2 * self.base_depth, 5, strides=2, padding='same', activation=tf.nn.leaky_relu)\r\n",
        "    self.conv_5 = tfkl.Conv2D(4 * self.encoded_size, 7, strides=1, padding='valid', activation=tf.nn.leaky_relu)\r\n",
        "    self.flatten_layer = tfkl.Flatten()\r\n",
        "    self.dense_layer = tfkl.Dense(tfpl.MultivariateNormalTriL.params_size(self.encoded_size), activation=None)\r\n",
        "    self.output_layer = tfpl.MultivariateNormalTriL(self.encoded_size, activity_regularizer=tfpl.KLDivergenceRegularizer(self.prior))     #probability distribution\r\n",
        "\r\n",
        "  # Description: This function conducts\r\n",
        "  #              The python decorator @tf.function is used to bundle multiple computations into one computational graph.\r\n",
        "  #              @parameters: (input) x, training necessary??????????????\r\n",
        "  #              @returns: (prediction) x\r\n",
        "  #@tf.function\r\n",
        "  def call(self, x, training = True):\r\n",
        "    x = self.input_layer(x)\r\n",
        "    x = self.lambda_layer(x)\r\n",
        "    x = self.conv_1(x)\r\n",
        "    x = self.conv_2(x)\r\n",
        "    x = self.conv_3(x)\r\n",
        "    x = self.conv_4(x)\r\n",
        "    x = self.conv_5(x)\r\n",
        "    x = self.flatten_layer(x)\r\n",
        "    x = self.dense_layer(x)\r\n",
        "    x = self.output_layer(x)\r\n",
        "    return x "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sQVmw_oIs7q"
      },
      "source": [
        "Class Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3npY20sCIu3T"
      },
      "source": [
        "# Description: The class Decoder defines the decoder of a variational autoencoder.\r\n",
        "class Decoder(tf.keras.layers.Layer): \r\n",
        "  \r\n",
        "  def __init__(self):\r\n",
        "    super(Decoder, self).__init__()\r\n",
        "\r\n",
        "    self.encoded_size = 10\r\n",
        "    self.base_depth = 32\r\n",
        "\r\n",
        "    self.input_layer = tfkl.InputLayer(input_shape=[self.encoded_size])\r\n",
        "    self.reshape_layer = tfkl.Reshape([1, 1, self.encoded_size])\r\n",
        "    self.transp_conv_1 = tfkl.Conv2DTranspose(2 * self.base_depth, 7, strides=1, padding='valid', activation=tf.nn.leaky_relu)\r\n",
        "    self.transp_conv_2 = tfkl.Conv2DTranspose(2 * self.base_depth, 5, strides=1, padding='same', activation=tf.nn.leaky_relu)\r\n",
        "    self.transp_conv_3 = tfkl.Conv2DTranspose(2 * self.base_depth, 5, strides=2, padding='same', activation=tf.nn.leaky_relu)\r\n",
        "    self.transp_conv_4 = tfkl.Conv2DTranspose(self.base_depth, 5, strides=1, padding='same', activation=tf.nn.leaky_relu)\r\n",
        "    self.transp_conv_5 = tfkl.Conv2DTranspose(self.base_depth, 5, strides=2, padding='same', activation=tf.nn.leaky_relu)\r\n",
        "    self.transp_conv_6 = tfkl.Conv2DTranspose(self.base_depth, 5, strides=1, padding='same', activation=tf.nn.leaky_relu)\r\n",
        "    self.conv_1 = tfkl.Conv2D(filters=1, kernel_size=5, strides=1, padding='same', activation=None)\r\n",
        "    self.flatten_layer = tfkl.Flatten()\r\n",
        "    self.output_layer = tfpl.IndependentBernoulli((28, 28, 1), tfd.Bernoulli.logits)\r\n",
        "\r\n",
        "  # Description: This function conducts\r\n",
        "  #              The python decorator @tf.function is used to bundle multiple computations into one computational graph.\r\n",
        "  #              @parameters: (input) x, training necessary??????????????\r\n",
        "  #              @returns: (prediction) x\r\n",
        "  #@tf.function\r\n",
        "  def call(self, x, training = True):\r\n",
        "    x = self.input_layer(x)\r\n",
        "    x = self.reshape_layer(x)\r\n",
        "    x = self.transp_conv_1(x)\r\n",
        "    x = self.transp_conv_2(x)\r\n",
        "    x = self.transp_conv_3(x)\r\n",
        "    x = self.transp_conv_4(x)\r\n",
        "    x = self.transp_conv_5(x)\r\n",
        "    x = self.transp_conv_6(x)\r\n",
        "    x = self.conv_1(x)\r\n",
        "    x = self.flatten_layer(x)\r\n",
        "    x = self.output_layer(x)\r\n",
        "    return x"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wviVt32ALX1p"
      },
      "source": [
        "Class Variational Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtwmxbnhLa0Z"
      },
      "source": [
        "# Description: The class VarAutoencoder defines the variational autoencoder consisting of an encoder and a decoder.\r\n",
        "class VarAutoencoder(tf.keras.Model): \r\n",
        "  \r\n",
        "  def __init__(self):\r\n",
        "    super(VarAutoencoder, self).__init__()\r\n",
        "\r\n",
        "    self.encoder = Encoder()\r\n",
        "    self.decoder = Decoder()\r\n",
        "\r\n",
        "  # Description: This function conducts \r\n",
        "  #              The python decorator @tf.function is used to bundle multiple computations into one computational graph.\r\n",
        "  #              @parameters: (input) x, training necessary??????????????\r\n",
        "  #              @returns: (prediction) x\r\n",
        "  #@tf.function\r\n",
        "  def call(self, x, training = True):\r\n",
        "    embeddings = self.encoder(x)\r\n",
        "    output = self.decoder(embeddings)\r\n",
        "\r\n",
        "    return output, embeddings  "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8L5R0JPsQotf"
      },
      "source": [
        "**ONLINE SOURCE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O272cXGSsHhv",
        "outputId": "73ae1670-197e-4f23-ddea-b3aa96f30c99"
      },
      "source": [
        "encoded_size = 10\r\n",
        "base_depth = 32\r\n",
        "\r\n",
        "prior = tfd.Independent(tfd.Normal(loc=tf.zeros(encoded_size), scale=1),\r\n",
        "                        reinterpreted_batch_ndims=1)\r\n",
        "\r\n",
        "encoder = tfk.Sequential([\r\n",
        "    tfkl.InputLayer(input_shape=(28, 28, 1)),\r\n",
        "    tfkl.Lambda(lambda x: tf.cast(x, tf.float32) - 0.5),\r\n",
        "    tfkl.Conv2D(base_depth, 5, strides=1, padding='same', activation=tf.nn.leaky_relu),\r\n",
        "    tfkl.Conv2D(base_depth, 5, strides=2, padding='same', activation=tf.nn.leaky_relu),\r\n",
        "    tfkl.Conv2D(2 * base_depth, 5, strides=1, padding='same', activation=tf.nn.leaky_relu),\r\n",
        "    tfkl.Conv2D(2 * base_depth, 5, strides=2, padding='same', activation=tf.nn.leaky_relu),\r\n",
        "    tfkl.Conv2D(4 * encoded_size, 7, strides=1, padding='valid', activation=tf.nn.leaky_relu),\r\n",
        "    tfkl.Flatten(),\r\n",
        "    tfkl.Dense(tfpl.MultivariateNormalTriL.params_size(encoded_size), activation=None),\r\n",
        "    tfpl.MultivariateNormalTriL( encoded_size, activity_regularizer=tfpl.KLDivergenceRegularizer(prior)),\r\n",
        "])\r\n",
        "\r\n",
        "decoder = tfk.Sequential([\r\n",
        "    tfkl.InputLayer(input_shape=[encoded_size]),\r\n",
        "    tfkl.Reshape([1, 1, encoded_size]),\r\n",
        "    tfkl.Conv2DTranspose(2 * base_depth, 7, strides=1, padding='valid', activation=tf.nn.leaky_relu),\r\n",
        "    tfkl.Conv2DTranspose(2 * base_depth, 5, strides=1, padding='same', activation=tf.nn.leaky_relu),\r\n",
        "    tfkl.Conv2DTranspose(2 * base_depth, 5, strides=2, padding='same', activation=tf.nn.leaky_relu),\r\n",
        "    tfkl.Conv2DTranspose(base_depth, 5, strides=1, padding='same', activation=tf.nn.leaky_relu),\r\n",
        "    tfkl.Conv2DTranspose(base_depth, 5, strides=2, padding='same', activation=tf.nn.leaky_relu),\r\n",
        "    tfkl.Conv2DTranspose(base_depth, 5, strides=1, padding='same', activation=tf.nn.leaky_relu),\r\n",
        "    tfkl.Conv2D(filters=1, kernel_size=5, strides=1, padding='same', activation=None),\r\n",
        "    tfkl.Flatten(),\r\n",
        "    tfpl.IndependentBernoulli((28, 28, 1), tfd.Bernoulli.logits),\r\n",
        "])\r\n",
        "\r\n",
        "vae = tfk.Model(inputs=encoder.inputs, outputs=decoder(encoder.outputs[0]))\r\n",
        "\r\n",
        "negloglik = lambda x, rv_x: -rv_x.log_prob(x)\r\n",
        "\r\n",
        "vae.compile(optimizer=tf.optimizers.Adam(learning_rate=1e-3), loss=negloglik)\r\n",
        "\r\n",
        "_ = vae.fit(training_dataset, epochs=10, validation_data=test_dataset)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/linalg/linear_operator_lower_triangular.py:158: calling LinearOperator.__init__ (from tensorflow.python.ops.linalg.linear_operator) with graph_parents is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Do not pass `graph_parents`.  They will  no longer be used.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/linalg/linear_operator_lower_triangular.py:158: calling LinearOperator.__init__ (from tensorflow.python.ops.linalg.linear_operator) with graph_parents is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Do not pass `graph_parents`.  They will  no longer be used.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "235/235 [==============================] - 13s 57ms/step - loss: 327.6652 - val_loss: 274.3146\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 12s 53ms/step - loss: 265.6744 - val_loss: 263.2408\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 13s 54ms/step - loss: 260.7886 - val_loss: 260.7799\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 13s 54ms/step - loss: 258.3408 - val_loss: 258.7775\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 13s 53ms/step - loss: 256.6294 - val_loss: 257.6094\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 12s 53ms/step - loss: 255.6436 - val_loss: 256.8476\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 12s 53ms/step - loss: 255.0533 - val_loss: 256.1284\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 13s 53ms/step - loss: 254.4957 - val_loss: 255.1877\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 12s 53ms/step - loss: 253.9610 - val_loss: 255.0211\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 12s 53ms/step - loss: 253.5822 - val_loss: 254.8511\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMoAiXRr9jRl"
      },
      "source": [
        "**Task 3 and 4: Training and Latent Space Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqTfqlnG9n7C"
      },
      "source": [
        "# Description: This function conducts a forward-step and the backpropagation. Additionally, the average training loss and accuracy is determined.\r\n",
        "#              @parameters: model, training_data, loss_fn, optimizer, training \r\n",
        "#              @returns: training_loss, training_accuracy\r\n",
        "#@tf.function\r\n",
        "def training_step(model, training_data, loss_fn, optimizer, training = True):\r\n",
        "  training_losses = []\r\n",
        "  #training_accuracies = []\r\n",
        "\r\n",
        "  for (input, target) in training_data:\r\n",
        "    with tf.GradientTape() as tape:\r\n",
        "      prediction, _ = model(input, training)                                                      # Embedded input is not relevant during training.                                                    \r\n",
        "      current_training_loss = loss_fn(input, prediction) #+ tf.math.reduce_sum(model.losses)    # loss is calculated between original image (input) and the predicted image (prediction)\r\n",
        "      gradients = tape.gradient(current_training_loss, model.trainable_variables)\r\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\r\n",
        "\r\n",
        "    training_losses.append(current_training_loss.numpy())\r\n",
        "\r\n",
        "    #current_training_accuracy = np.argmax(target, axis=1) == np.argmax(prediction, axis=1)\r\n",
        "    #training_accuracies.append(np.mean(current_training_accuracy))  \r\n",
        "  \r\n",
        "  training_loss = np.mean(training_losses)\r\n",
        "  #training_accuracy = np.mean(training_accuracies)\r\n",
        "  return training_loss #, training_accuracy\r\n",
        "\r\n",
        "\r\n",
        "# Description: This function determines the average test loss and accuracy of an autoencoder.\r\n",
        "#              @parameters: model, test_data, loss_fn, training\r\n",
        "#              @returns: test_loss, test_accuracy\r\n",
        "#@tf.function\r\n",
        "def test(model, test_data, loss_fn, training = False):\r\n",
        "  test_losses = []\r\n",
        "  #test_accuracies = []\r\n",
        "  embeddings = []\r\n",
        "  corresponding_embedding_labels = []\r\n",
        "\r\n",
        "  test_image_counter = 0\r\n",
        "  example_input_img = tf.zeros([28, 28, 1], tf.int32)\r\n",
        "  example_prediction_img = tf.zeros([28, 28, 1], tf.int32)\r\n",
        "  for (input, target) in test_data:\r\n",
        "    prediction, embedded_input = model(input, training)                                       # Embedded input is relevant during testing.\r\n",
        "\r\n",
        "    current_test_loss = loss_fn(input, prediction)\r\n",
        "    test_losses.append(current_test_loss.numpy())\r\n",
        "\r\n",
        "    #current_test_accuracy = np.argmax(target, axis=1) == np.argmax(prediction, axis=1)\r\n",
        "    #test_accuracies.append(np.mean(current_test_accuracy))   \r\n",
        "\r\n",
        "    if test_image_counter < 1000:                                           # The first 1000 embedded test images are used for the latent space analysis.\r\n",
        "      embeddings.append(embedded_input)\r\n",
        "      corresponding_embedding_labels.append(target)\r\n",
        "      test_image_counter += batch_size\r\n",
        "\r\n",
        "      if test_image_counter == 1000:                                        # One original image and predicted image pair is printed per test epoch to get an overview over the training progress. \r\n",
        "        example_input_img = input[batch_size - 1]\r\n",
        "        example_prediction_img = prediction[batch_size - 1]\r\n",
        "    \r\n",
        "  test_loss = np.mean(test_losses)\r\n",
        "  #test_accuracy = np.mean(test_accuracies)\r\n",
        "  return test_loss, example_input_img, example_prediction_img, embeddings, corresponding_embedding_labels   #, test_accuracy"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_H2Hgdr4_AVH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "outputId": "cfe0e636-3d7d-4977-c243-056bb1b32945"
      },
      "source": [
        "# Description: This part creates objects of ....... and executes the training and testing of these models in the training and test loop. The training \r\n",
        "#              takes place over an amount of epochs (n_epochs) with a predefined learning rate. The loss function defines the kind of loss-calculation. The optimizer \r\n",
        "#              is needed to adjust the gradients in the training steps. Moreover, the data for the visualization of the training and test progress is collected.\r\n",
        "#              In order to better monitor the training progress, the loss and accuracy graphs are provided in addtion to the numerical outputs when the test accuracy \r\n",
        "#              has significantly improved.\r\n",
        "tf.keras.backend.clear_session()\r\n",
        "\r\n",
        "model = VarAutoencoder()\r\n",
        "\r\n",
        "n_epochs = 10\r\n",
        "learning_rate = 0.001\r\n",
        "loss_fn = lambda x, rv_x: -rv_x.log_prob(x) #tf.keras.losses.MeanSquaredError()                             # Mean squared error as loss-function.\r\n",
        "optimizer = tf.keras.optimizers.Adam((learning_rate), amsgrad = True)    # Optimizer Adam (Adaptive Moment Estimation) with AMSGrad activated.\r\n",
        "\r\n",
        "training_losses = []\r\n",
        "#training_accuracies = []\r\n",
        "test_losses = []\r\n",
        "#test_accuracies = []\r\n",
        "\r\n",
        "# Training and test loop\r\n",
        "for epoch in range(n_epochs):\r\n",
        "    print('Epoch ' + str(epoch))\r\n",
        "\r\n",
        "    training_loss = training_step(model, training_dataset, loss_fn, optimizer, training = True)   #, training_accuracy \r\n",
        "    training_losses.append(training_loss)\r\n",
        "    #training_accuracies.append(training_accuracy)\r\n",
        "\r\n",
        "    test_loss, example_input_img, example_prediction_img, embeddings, corresponding_embedding_labels = test(model, test_dataset, loss_fn, training = False)                              #, test_accuracy\r\n",
        "    test_losses.append(test_loss)\r\n",
        "    #test_accuracies.append(test_accuracy)\r\n",
        "\r\n",
        "    embeddings = tf.reshape(embeddings, [1000, 10])\r\n",
        "    corresponding_embedding_labels = tf.reshape(corresponding_embedding_labels, [1000])\r\n",
        "    reduced_embeddings = TSNE(n_components = 2).fit_transform(embeddings)\r\n",
        "\r\n",
        "    plt.imshow(tf.squeeze(example_input_img).numpy())\r\n",
        "    plt.show()\r\n",
        "    plt.imshow(tf.squeeze(example_prediction_img).numpy())\r\n",
        "    plt.show()\r\n",
        "\r\n",
        "    label_color_coding = [\"black\", \"brown\", \"red\", \"blue\", \"lime\", \"yellow\", \"darkorange\", \"cyan\", \"darkviolet\", \"deeppink\"]\r\n",
        "    for embed in range(1000):\r\n",
        "      current_label_color = label_color_coding[corresponding_embedding_labels[embed]]\r\n",
        "      plt.scatter(reduced_embeddings[embed][0], reduced_embeddings[embed][1], color = current_label_color)\r\n",
        "    plt.show()\r\n",
        "\r\n",
        "    # Interpolation check between two images in a seperate function which does the same like a test step, but just for two images and without all the loss shit and so on.. And I need an additional seperation in the call function of the autoencoder (another boolean??) -> after the encoder I need to interpolate the two vectors and then apply the decoder.\r\n",
        "\r\n",
        "    print(\"Training loss: \" + str(training_loss))\r\n",
        "    print(\"Test loss: \" + str(test_loss))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-82bb5d2fd9d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mtraining_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m#, training_accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mtraining_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m#training_accuracies.append(training_accuracy)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-61666231d836>\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(model, training_data, loss_fn, optimizer, training)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m#training_accuracies.append(np.mean(current_training_accuracy))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m   \u001b[0mtraining_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m   \u001b[0;31m#training_accuracy = np.mean(training_accuracies)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtraining_loss\u001b[0m \u001b[0;31m#, training_accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmean\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   3333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3334\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[0;32m-> 3335\u001b[0;31m                           out=out, **kwargs)\n\u001b[0m\u001b[1;32m   3336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mis_float16_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         ret = um.true_divide(\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (256,) (96,) "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpzajPTAmodS"
      },
      "source": [
        "Visualization\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8r0FzUXZmxcD"
      },
      "source": [
        "# Description: Figure 1 shows the loss for each epoch during the training and testing of the model.\r\n",
        "#              Figure 2 shows the accuracy for each epoch during the training and testing of the model.\r\n",
        "plt.figure()\r\n",
        "line1, = plt.plot(training_losses)\r\n",
        "line2, = plt.plot(test_losses)\r\n",
        "plt.xlabel(\"Training steps\")\r\n",
        "plt.ylabel(\"Loss\")\r\n",
        "plt.legend((line1, line2),(\"Training\", \"Test\"))\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}